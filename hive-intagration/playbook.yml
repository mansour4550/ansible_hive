---
- name: Integrate Hive with Apache Atlas
  hosts: all
  become: yes
  vars:
    atlas_tarball: apache-atlas-2.4.0-hive-hook.tar.gz
    atlas_install_dir: /opt/apache-atlas-2.4.0
    hive_install_dir: /opt/apache-hive-3.1.3-bin
    hadoop_user: hadoopZetta
    hadoop_group: hadoopZetta
    atlas_source_dir: /home/hadoopZetta

  tasks:
    # Tasks on master1: Transfer files to edge1
    - name: Transfer tarball and atlas-application.properties from master1 to edge1
      when: inventory_hostname == '192.168.10.110'
      become_user: hadoopZetta
      ansible.builtin.copy:
        src: "{{ item.src }}"
        dest: "/home/{{ hadoop_user }}/{{ item.dest }}"
        mode: '0644'
      loop:
        - { src: '{{ atlas_source_dir }}/{{ atlas_tarball }}', dest: '{{ atlas_tarball }}' }
        - { src: '{{ atlas_install_dir }}/conf/atlas-application.properties', dest: 'atlas-application.properties' }
      delegate_to: 192.168.10.113

    # Tasks on edge1
    - name: Verify tarball on edge1
      when: inventory_hostname == '192.168.10.113'
      become_user: hadoopZetta
      ansible.builtin.stat:
        path: "{{ atlas_source_dir }}/{{ atlas_tarball }}"
      register: tarball_stat

    - name: Fail if tarball is missing
      when: inventory_hostname == '192.168.10.113'
      ansible.builtin.fail:
        msg: "Tarball {{ atlas_tarball }} not found on edge1"
      when: not tarball_stat.stat.exists

    - name: Extract Atlas Hive hook tarball
      when: inventory_hostname == '192.168.10.113'
      ansible.builtin.unarchive:
        src: "{{ atlas_source_dir }}/{{ atlas_tarball }}"
        dest: /opt/
        owner: "{{ hadoop_user }}"
        group: "{{ hadoop_group }}"
        mode: '0755'
        creates: "{{ atlas_install_dir }}/hook"

    - name: Create Atlas hook directory
      when: inventory_hostname == '192.168.10.113'
      ansible.builtin.file:
        path: "{{ atlas_install_dir }}/hook"
        state: directory
        owner: "{{ hadoop_user }}"
        group: "{{ hadoop_group }}"
        mode: '0755'

    - name: Create Atlas Hive hook subdirectory
      when: inventory_hostname == '192.168.10.113'
      ansible.builtin.file:
        path: "{{ atlas_install_dir }}/hook/hive"
        state: directory
        owner: "{{ hadoop_user }}"
        group: "{{ hadoop_group }}"
        mode: '0755'

    - name: Copy Hive hook files to Atlas
      when: inventory_hostname == '192.168.10.113'
      ansible.builtin.copy:
        src: "/opt/apache-atlas-hive-hook-2.4.0/hook/hive/"
        dest: "{{ atlas_install_dir }}/hook/hive/"
        owner: "{{ hadoop_user }}"
        group: "{{ hadoop_group }}"
        mode: '0755'

    - name: Copy hook JARs to Hive lib
      when: inventory_hostname == '192.168.10.113'
      ansible.builtin.copy:
        src: "{{ atlas_install_dir }}/hook/hive/{{ item }}"
        dest: "{{ hive_install_dir }}/lib/{{ item }}"
        owner: "{{ hadoop_user }}"
        group: "{{ hadoop_group }}"
        mode: '0644'
      loop:
        - atlas-hive-hook-2.4.0.jar
        - atlas-plugin-classloader-2.4.0.jar
        - hive-bridge-shim-2.4.0.jar

    - name: Copy atlas-hive-plugin-impl directory to Hive lib
      when: inventory_hostname == '192.168.10.113'
      ansible.builtin.copy:
        src: "{{ atlas_install_dir }}/hook/hive/atlas-hive-plugin-impl/"
        dest: "{{ hive_install_dir }}/lib/atlas-hive-plugin-impl/"
        owner: "{{ hadoop_user }}"
        group: "{{ hadoop_group }}"
        mode: '0755'

    - name: Set hive.security.authorization.enabled to false
      when: inventory_hostname == '192.168.10.113'
      ansible.builtin.replace:
        path: "{{ hive_install_dir }}/conf/hive-site.xml"
        regexp: '(<property>\s*<name>hive\.security\.authorization\.enabled</name>\s*<value>)true(</value>\s*</property>)'
        replace: '\1false\2'
        backup: yes
      ignore_errors: yes # In case the property doesn't exist

    - name: Add Atlas Hive hook to hive-site.xml
      when: inventory_hostname == '192.168.10.113'
      ansible.builtin.lineinfile:
        path: "{{ hive_install_dir }}/conf/hive-site.xml"
        line: |
          <property>
            <name>hive.exec.post.hooks</name>
            <value>org.apache.atlas.hive.hook.HiveHook</value>
          </property>
        insertbefore: '</configuration>'
        state: present
        create: yes
        owner: "{{ hadoop_user }}"
        group: "{{ hadoop_group }}"
        mode: '0644'

    - name: Set HIVE_AUX_JARS_PATH in hive-env.sh
      when: inventory_hostname == '192.168.10.113'
      ansible.builtin.lineinfile:
        path: "{{ hive_install_dir }}/conf/hive-env.sh"
        line: "export HIVE_AUX_JARS_PATH={{ atlas_install_dir }}/hook/hive"
        state: present
        create: yes
        owner: "{{ hadoop_user }}"
        group: "{{ hadoop_group }}"
        mode: '0755'

    - name: Copy atlas-application.properties to Hive conf
      when: inventory_hostname == '192.168.10.113'
      ansible.builtin.copy:
        src: "{{ atlas_source_dir }}/atlas-application.properties"
        dest: "{{ hive_install_dir }}/conf/atlas-application.properties"
        owner: "{{ hadoop_user }}"
        group: "{{ hadoop_group }}"
        mode: '0644'

    - name: Update atlas-application.properties with new IP addresses
      when: inventory_hostname == '192.168.10.113'
      ansible.builtin.blockinfile:
        path: "{{ hive_install_dir }}/conf/atlas-application.properties"
        block: |
          atlas.graph.storage.hostname=192.168.10.115:2181
          atlas.kafka.zookeeper.connect=192.168.10.115:2181
          atlas.kafka.bootstrap.servers=192.168.10.115:9092
          atlas.graph.index.search.solr.zookeeper-url=192.168.10.115:2181
          atlas.graph.index.search.solr.http-urls=http://192.168.10.115:8983/solr
          atlas.server.address.id1=192.168.10.110:21000
          atlas.server.address.id2=192.168.10.111:21000
        marker: "# {mark} ANSIBLE MANAGED BLOCK"

    - name: Create Atlas hook-bin directory
      when: inventory_hostname == '192.168.10.113'
      ansible.builtin.file:
        path: "{{ atlas_install_dir }}/hook-bin"
        state: directory
        owner: "{{ hadoop_user }}"
        group: "{{ hadoop_group }}"
        mode: '0755'

    - name: Download log4j JAR
      when: inventory_hostname == '192.168.10.113'
      ansible.builtin.get_url:
        url: http://archive.apache.org/dist/logging/log4j/1.2.17/log4j-1.2.17.jar
        dest: "{{ atlas_install_dir }}/hook-bin/log4j-1.2.17.jar"
        owner: "{{ hadoop_user }}"
        group: "{{ hadoop_group }}"
        mode: '0644'

    - name: Download slf4j-log4j12 JAR
      when: inventory_hostname == '192.168.10.113'
      ansible.builtin.get_url:
        url: https://repo1.maven.org/maven2/org/slf4j/slf4j-log4j12/1.7.30/slf4j-log4j12-1.7.30.jar
        dest: "{{ atlas_install_dir }}/hook-bin/slf4j-log4j12-1.7.30.jar"
        owner: "{{ hadoop_user }}"
        group: "{{ hadoop_group }}"
        mode: '0644'

    - name: Copy import-hive.sh to hook-bin
      when: inventory_hostname == '192.168.10.113'
      ansible.builtin.copy:
        src: "/opt/apache-atlas-hive-hook-2.4.0/hook-bin/import-hive.sh"
        dest: "{{ atlas_install_dir }}/hook-bin/import-hive.sh"
        owner: "{{ hadoop_user }}"
        group: "{{ hadoop_group }}"
        mode: '0755'

    - name: Stop HiveServer2 on edge1
      when: inventory_hostname == '192.168.10.113'
      ansible.builtin.command: pkill -f HiveServer2
      ignore_errors: yes

    - name: Start HiveServer2 on edge1
      when: inventory_hostname == '192.168.10.113'
      ansible.builtin.command: "{{ hive_install_dir }}/bin/hiveserver2 &"
      async: 45
      poll: 0

    - name: Stop Hive Metastore on master nodes
      when: inventory_hostname in ['192.168.10.110', '192.168.10.111', '192.168.10.112']
      ansible.builtin.command: pkill -f HiveMetastore
      ignore_errors: yes

    - name: Start Hive Metastore on master nodes
      when: inventory_hostname in ['192.168.10.110', '192.168.10.111', '192.168.10.112']
      ansible.builtin.command: "{{ hive_install_dir }}/bin/hive --service metastore &"
      async: 45
      poll: 0

    - name: Test Hive by creating a test database and table
      when: inventory_hostname == '192.168.10.113'
      become_user: hadoopZetta
      ansible.builtin.shell: |
        hive <<EOF
        CREATE DATABASE test_db;
        USE test_db;
        CREATE TABLE test255 (id INT);
        EOF
      changed_when: false
      ignore_errors: yes

    - name: Import Hive metadata to Atlas
      when: inventory_hostname == '192.168.10.113'
      become_user: hadoopZetta
      ansible.builtin.shell: |
        export HIVE_HOME={{ hive_install_dir }}
        export ATLAS_HOME={{ atlas_install_dir }}
        {{ atlas_install_dir }}/hook-bin/import-hive.sh
      changed_when: false

    - name: Display Atlas UI verification message
      when: inventory_hostname == '192.168.10.113'
      ansible.builtin.debug:
        msg: "Verify in Atlas UI at http://192.168.10.110:21000 or http://192.168.10.111:21000"